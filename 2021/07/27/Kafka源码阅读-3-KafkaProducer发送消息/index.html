<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="en">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Kafka,源码," />










<meta name="description" content="KafkaProducer发送消息的过程简析">
<meta property="og:type" content="article">
<meta property="og:title" content="Kafka源码阅读-3-KafkaProducer发送消息">
<meta property="og:url" content="http://yoursite.com/2021/07/27/Kafka%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB-3-KafkaProducer%E5%8F%91%E9%80%81%E6%B6%88%E6%81%AF/index.html">
<meta property="og:site_name" content="llrrbaba">
<meta property="og:description" content="KafkaProducer发送消息的过程简析">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://i.loli.net/2021/08/20/QpHkxqmgZGU4FVz.png">
<meta property="article:published_time" content="2021-07-27T13:15:04.000Z">
<meta property="article:modified_time" content="2021-08-20T15:50:02.956Z">
<meta property="article:author" content="llrrbaba">
<meta property="article:tag" content="Kafka">
<meta property="article:tag" content="源码">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://i.loli.net/2021/08/20/QpHkxqmgZGU4FVz.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2021/07/27/Kafka源码阅读-3-KafkaProducer发送消息/"/>





  <title>Kafka源码阅读-3-KafkaProducer发送消息 | llrrbaba</title>
  








<meta name="generator" content="Hexo 4.2.0"></head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">llrrbaba</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-首页">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-关于">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-标签">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-分类">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-归档">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2021/07/27/Kafka%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB-3-KafkaProducer%E5%8F%91%E9%80%81%E6%B6%88%E6%81%AF/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="llrrbaba">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="llrrbaba">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Kafka源码阅读-3-KafkaProducer发送消息</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2021-07-27T21:15:04+08:00">
                2021-07-27
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Kafka/" itemprop="url" rel="index">
                    <span itemprop="name">Kafka</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>KafkaProducer发送消息的过程简析</p>
<a id="more"></a>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// org.apache.kafka.clients.producer.KafkaProducer#send(org.apache.kafka.clients.producer.ProducerRecord&lt;K,V&gt;)</span></span><br><span class="line"><span class="comment">// 发送消息，可以发现，发送消息是个异步的方法，返回的是一个future对象</span></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Future&lt;RecordMetadata&gt; <span class="title">send</span><span class="params">(ProducerRecord&lt;K, V&gt; record)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> send(record, <span class="keyword">null</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// org.apache.kafka.clients.producer.KafkaProducer#send(org.apache.kafka.clients.producer.ProducerRecord&lt;K,V&gt;, org.apache.kafka.clients.producer.Callback)</span></span><br><span class="line"><span class="comment">// 上面的方法其实是调用的这个方法，只不过没有提供callback实现，</span></span><br><span class="line"><span class="comment">// broker经过ack之后，会回调这个callBack</span></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Future&lt;RecordMetadata&gt; <span class="title">send</span><span class="params">(ProducerRecord&lt;K, V&gt; record, Callback callback)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// intercept the record, which can be potentially modified; this method does not throw exceptions</span></span><br><span class="line">    ProducerRecord&lt;K, V&gt; interceptedRecord = <span class="keyword">this</span>.interceptors == <span class="keyword">null</span> ? record : <span class="keyword">this</span>.interceptors.onSend(record);</span><br><span class="line">    <span class="keyword">return</span> doSend(interceptedRecord, callback);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// org.apache.kafka.clients.producer.KafkaProducer#doSend</span></span><br><span class="line"><span class="comment">// 发送消息的真正实现，可以看到是个私有方法，不对外暴露</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 消息是被首先存储到缓冲区里。这样能够减少io等待，提升并发发送消息的速度。</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> Future&lt;RecordMetadata&gt; <span class="title">doSend</span><span class="params">(ProducerRecord&lt;K, V&gt; record, Callback callback)</span> </span>&#123;</span><br><span class="line">    TopicPartition tp = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// first make sure the metadata for the topic is available</span></span><br><span class="line">        <span class="comment">// 发送消息前，首先要去获取下元数据，确认我们要发送消息的topic对应的元数据是准备就绪的</span></span><br><span class="line">        <span class="keyword">long</span> waitedOnMetadataMs = waitOnMetadata(record.topic(), <span class="keyword">this</span>.maxBlockTimeMs);</span><br><span class="line">        <span class="comment">// 拉取元数据之后剩余的时间</span></span><br><span class="line">        <span class="keyword">long</span> remainingWaitMs = Math.max(<span class="number">0</span>, <span class="keyword">this</span>.maxBlockTimeMs - waitedOnMetadataMs);</span><br><span class="line">        <span class="keyword">byte</span>[] serializedKey;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">// 将 key 序列化</span></span><br><span class="line">            serializedKey = keySerializer.serialize(record.topic(), record.key());</span><br><span class="line">        &#125; <span class="keyword">catch</span> (ClassCastException cce) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> SerializationException(<span class="string">"Can't convert key of class "</span> + record.key().getClass().getName() +</span><br><span class="line">                    <span class="string">" to class "</span> + producerConfig.getClass(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG).getName() +</span><br><span class="line">                    <span class="string">" specified in key.serializer"</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">byte</span>[] serializedValue;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">// 将 value 序列化</span></span><br><span class="line">            serializedValue = valueSerializer.serialize(record.topic(), record.value());</span><br><span class="line">        &#125; <span class="keyword">catch</span> (ClassCastException cce) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> SerializationException(<span class="string">"Can't convert value of class "</span> + record.value().getClass().getName() +</span><br><span class="line">                    <span class="string">" to class "</span> + producerConfig.getClass(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG).getName() +</span><br><span class="line">                    <span class="string">" specified in value.serializer"</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 获取要投递到的分区</span></span><br><span class="line">        <span class="keyword">int</span> partition = partition(record, serializedKey, serializedValue, metadata.fetch());</span><br><span class="line">        <span class="keyword">int</span> serializedSize = Records.LOG_OVERHEAD + Record.recordSize(serializedKey, serializedValue);</span><br><span class="line">        <span class="comment">// 校验下消息大小，别超标了</span></span><br><span class="line">        ensureValidRecordSize(serializedSize);</span><br><span class="line">        <span class="comment">// 封装 TopicPartition 信息</span></span><br><span class="line">        tp = <span class="keyword">new</span> TopicPartition(record.topic(), partition);</span><br><span class="line">        <span class="comment">// 获取一个时间，如果在record指定了的话，可以用自己指定的时间</span></span><br><span class="line">        <span class="keyword">long</span> timestamp = record.timestamp() == <span class="keyword">null</span> ? time.milliseconds() : record.timestamp();</span><br><span class="line">        log.trace(<span class="string">"Sending record &#123;&#125; with callback &#123;&#125; to topic &#123;&#125; partition &#123;&#125;"</span>, record, callback, record.topic(), partition);</span><br><span class="line">        <span class="comment">// producer callback will make sure to call both 'callback' and interceptor callback</span></span><br><span class="line">        <span class="comment">// 如果我们在构建kafkaProducer的时候，指定了拦截器的话，这里会将拦截器和回调方法维护到一块</span></span><br><span class="line">        <span class="comment">// 如果没有指定拦截器的话，这里就只有我们出入的回调方法了</span></span><br><span class="line">        Callback interceptCallback = <span class="keyword">this</span>.interceptors == <span class="keyword">null</span> ? callback : <span class="keyword">new</span> InterceptorCallback&lt;&gt;(callback, <span class="keyword">this</span>.interceptors, tp);</span><br><span class="line">        <span class="comment">// 将我们要发送的消息添加到缓存里</span></span><br><span class="line">        <span class="comment">// RecordAccumulator里存放的都是还没发送到broker上的消息</span></span><br><span class="line">        RecordAccumulator.RecordAppendResult result = accumulator.append(tp, timestamp, serializedKey, serializedValue, interceptCallback, remainingWaitMs);</span><br><span class="line">        <span class="keyword">if</span> (result.batchIsFull || result.newBatchCreated) &#123;</span><br><span class="line">            <span class="comment">// result.batchIsFull，accumulator里的batched只要大于1就是true</span></span><br><span class="line">            log.trace(<span class="string">"Waking up the sender since topic &#123;&#125; partition &#123;&#125; is either full or getting a new batch"</span>, record.topic(), partition);</span><br><span class="line">            <span class="comment">// 唤醒 sender</span></span><br><span class="line">            <span class="comment">// sender实现了 Runnable接口</span></span><br><span class="line">            <span class="comment">// 并且和broker有很重要的交互</span></span><br><span class="line">            <span class="comment">// 发送消息到broker</span></span><br><span class="line">            <span class="comment">// 从broker集群拉取元数据信息，来更新客户端本地的元数据</span></span><br><span class="line">            <span class="comment">// 在KafkaProducer的构造函数里，我们看到，sender已经被包到KafkaThread里，</span></span><br><span class="line">            <span class="comment">// 并且已经调用了KafkaThread的start方法了</span></span><br><span class="line">            <span class="keyword">this</span>.sender.wakeup();</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 返回调用发送消息的结果</span></span><br><span class="line">        <span class="keyword">return</span> result.future;</span><br><span class="line">        <span class="comment">// handling exceptions and record the errors;</span></span><br><span class="line">        <span class="comment">// for API exceptions return them in the future,</span></span><br><span class="line">        <span class="comment">// for other exceptions throw directly</span></span><br><span class="line">    &#125; <span class="keyword">catch</span> (ApiException e) &#123;</span><br><span class="line">        log.debug(<span class="string">"Exception occurred during message send:"</span>, e);</span><br><span class="line">        <span class="keyword">if</span> (callback != <span class="keyword">null</span>)</span><br><span class="line">            callback.onCompletion(<span class="keyword">null</span>, e);</span><br><span class="line">        <span class="keyword">this</span>.errors.record();</span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">this</span>.interceptors != <span class="keyword">null</span>)</span><br><span class="line">            <span class="keyword">this</span>.interceptors.onSendError(record, tp, e);</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> FutureFailure(e);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">        <span class="keyword">this</span>.errors.record();</span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">this</span>.interceptors != <span class="keyword">null</span>)</span><br><span class="line">            <span class="keyword">this</span>.interceptors.onSendError(record, tp, e);</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> InterruptException(e);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (BufferExhaustedException e) &#123;</span><br><span class="line">        <span class="keyword">this</span>.errors.record();</span><br><span class="line">        <span class="keyword">this</span>.metrics.sensor(<span class="string">"buffer-exhausted-records"</span>).record();</span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">this</span>.interceptors != <span class="keyword">null</span>)</span><br><span class="line">            <span class="keyword">this</span>.interceptors.onSendError(record, tp, e);</span><br><span class="line">        <span class="keyword">throw</span> e;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (KafkaException e) &#123;</span><br><span class="line">        <span class="keyword">this</span>.errors.record();</span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">this</span>.interceptors != <span class="keyword">null</span>)</span><br><span class="line">            <span class="keyword">this</span>.interceptors.onSendError(record, tp, e);</span><br><span class="line">        <span class="keyword">throw</span> e;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">        <span class="comment">// we notify interceptor about all exceptions, since onSend is called before anything else in this method</span></span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">this</span>.interceptors != <span class="keyword">null</span>)</span><br><span class="line">            <span class="keyword">this</span>.interceptors.onSendError(record, tp, e);</span><br><span class="line">        <span class="keyword">throw</span> e;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>





<p><img src="https://i.loli.net/2021/08/20/QpHkxqmgZGU4FVz.png" alt="无标题流程图.png"></p>
<blockquote>
<p>简单贴一下缓存区里的对象关系吧</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// org.apache.kafka.clients.producer.internals.RecordAccumulator#append</span></span><br><span class="line"><span class="comment">// 将消息记录维护到accumulator里，返回一个result</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> RecordAppendResult <span class="title">append</span><span class="params">(TopicPartition tp,</span></span></span><br><span class="line"><span class="function"><span class="params">                                 <span class="keyword">long</span> timestamp,</span></span></span><br><span class="line"><span class="function"><span class="params">                                 <span class="keyword">byte</span>[] key,</span></span></span><br><span class="line"><span class="function"><span class="params">                                 <span class="keyword">byte</span>[] value,</span></span></span><br><span class="line"><span class="function"><span class="params">                                 Callback callback,</span></span></span><br><span class="line"><span class="function"><span class="params">                                 <span class="keyword">long</span> maxTimeToBlock)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">    <span class="comment">// We keep track of the number of appending thread to make sure we do not miss batches in</span></span><br><span class="line">    <span class="comment">// abortIncompleteBatches().</span></span><br><span class="line">    <span class="comment">// 记录发送消息的线程数目</span></span><br><span class="line">    appendsInProgress.incrementAndGet();</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// check if we have an in-progress batch</span></span><br><span class="line">        <span class="comment">// 获取指定tp对应的 recordBatch 队列</span></span><br><span class="line">        Deque&lt;RecordBatch&gt; dq = getOrCreateDeque(tp);</span><br><span class="line">        <span class="comment">// 对这个队列加个锁</span></span><br><span class="line">        <span class="keyword">synchronized</span> (dq) &#123;</span><br><span class="line">            <span class="comment">// 当我们调用kafkaProducer#close方法的时候，会设置这个closed为true</span></span><br><span class="line">            <span class="comment">// 也就不用再往accumulator里添加记录了</span></span><br><span class="line">            <span class="comment">// TODO 关闭KafkaProducer的时候，会处理accumulator里剩下的消息吗？</span></span><br><span class="line">            <span class="keyword">if</span> (closed)</span><br><span class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> IllegalStateException(<span class="string">"Cannot send after the producer is closed."</span>);</span><br><span class="line">            <span class="comment">// 尝试将消息添加到缓存里</span></span><br><span class="line">            RecordAppendResult appendResult = tryAppend(timestamp, key, value, callback, dq);</span><br><span class="line">            <span class="keyword">if</span> (appendResult != <span class="keyword">null</span>)</span><br><span class="line">                <span class="keyword">return</span> appendResult;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// we don't have an in-progress record batch try to allocate a new batch</span></span><br><span class="line">        <span class="comment">// 上面的tryAppend，我们实际上是从batches里找到最后一个，</span></span><br><span class="line">        <span class="comment">// 并试图将消息塞到最后一个recordBatch里.</span></span><br><span class="line">        <span class="comment">// 走到这里，说明，batches里可能就没有现成的recordBatch，</span></span><br><span class="line">        <span class="comment">// 或者有现成的recordBatch，但是满了</span></span><br><span class="line">        <span class="comment">// 那么我们就要开辟一段缓存空间，来给recordBatch使用</span></span><br><span class="line">        <span class="comment">// 获取batchSize</span></span><br><span class="line">        <span class="keyword">int</span> size = Math.max(<span class="keyword">this</span>.batchSize, Records.LOG_OVERHEAD + Record.recordSize(key, value));</span><br><span class="line">        log.trace(<span class="string">"Allocating a new &#123;&#125; byte message buffer for topic &#123;&#125; partition &#123;&#125;"</span>, size, tp.topic(), tp.partition());</span><br><span class="line">        <span class="comment">// 分配内存，大小就是我们刚刚指定的 size</span></span><br><span class="line">        ByteBuffer buffer = free.allocate(size, maxTimeToBlock);</span><br><span class="line">        <span class="keyword">synchronized</span> (dq) &#123;</span><br><span class="line">            <span class="comment">// Need to check if producer is closed again after grabbing the dequeue lock.</span></span><br><span class="line">            <span class="keyword">if</span> (closed)</span><br><span class="line">                <span class="comment">// 当我们调用kafkaProducer#close方法的时候，会设置这个closed为true</span></span><br><span class="line">            	<span class="comment">// 也就不用再往accumulator里添加记录了</span></span><br><span class="line">            	<span class="comment">// TODO 关闭KafkaProducer的时候，会处理accumulator里剩下的消息吗？</span></span><br><span class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> IllegalStateException(<span class="string">"Cannot send after the producer is closed."</span>);</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 在使用我们新开辟的内存之前，再次尝试将消息添加到缓存里</span></span><br><span class="line">            RecordAppendResult appendResult = tryAppend(timestamp, key, value, callback, dq);</span><br><span class="line">            <span class="keyword">if</span> (appendResult != <span class="keyword">null</span>) &#123;</span><br><span class="line">                <span class="comment">// Somebody else found us a batch, return the one we waited for! Hopefully this doesn't happen often...</span></span><br><span class="line">                <span class="comment">// 走到这里，竟然添加消息成功了</span></span><br><span class="line">                <span class="comment">// 说明41行之前有人已经开辟过内存了，所以这里要释放掉我们刚才开辟的内存</span></span><br><span class="line">                free.deallocate(buffer);</span><br><span class="line">                <span class="keyword">return</span> appendResult;</span><br><span class="line">            &#125;</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 新建了一个 memoryRecords，根据我们刚刚开辟的内存</span></span><br><span class="line">            MemoryRecords records = MemoryRecords.emptyRecords(buffer, compression, <span class="keyword">this</span>.batchSize);</span><br><span class="line">            <span class="comment">// 新建了一个 recordBatch，根据我们新建的 memoryRecords和指定的tp</span></span><br><span class="line">            RecordBatch batch = <span class="keyword">new</span> RecordBatch(tp, records, time.milliseconds());</span><br><span class="line">            <span class="comment">// OK，到这里，直接用我们新建的 recordBatch 来装我们的消息，没毛病</span></span><br><span class="line">            FutureRecordMetadata future = Utils.notNull(batch.tryAppend(timestamp, key, value, callback, time.milliseconds()));</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 将这个新建的 recordBatch添加到 dq尾部</span></span><br><span class="line">            dq.addLast(batch);</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 将我们的 recordBatch维护到未完成集合里</span></span><br><span class="line">            incomplete.add(batch);</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">new</span> RecordAppendResult(future, dq.size() &gt; <span class="number">1</span> || batch.records.isFull(), <span class="keyword">true</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        <span class="comment">// 记录发送消息的线程数目</span></span><br><span class="line">        appendsInProgress.decrementAndGet();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> RecordAppendResult <span class="title">tryAppend</span><span class="params">(<span class="keyword">long</span> timestamp, <span class="keyword">byte</span>[] key, <span class="keyword">byte</span>[] value, Callback callback, Deque&lt;RecordBatch&gt; deque)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 把对位的元素弹出来看看</span></span><br><span class="line">    RecordBatch last = deque.peekLast();</span><br><span class="line">    <span class="keyword">if</span> (last != <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="comment">// 如果走到这里，说明，这个tp对应的deque已经满了</span></span><br><span class="line">        <span class="comment">// 那么就用这个队列里的最后一个recordBatch看看，能不能把这条消息塞进去</span></span><br><span class="line">        FutureRecordMetadata future = last.tryAppend(timestamp, key, value, callback, time.milliseconds());</span><br><span class="line">        <span class="keyword">if</span> (future == <span class="keyword">null</span>)</span><br><span class="line">            <span class="comment">// 走到这里，说明没有塞进去，关闭这个最后的records</span></span><br><span class="line">            last.records.close();</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            <span class="comment">// 走到这里，说明消息已经塞进去缓存里了，返回结果</span></span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">new</span> RecordAppendResult(future, deque.size() &gt; <span class="number">1</span> || last.records.isFull(), <span class="keyword">false</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// org.apache.kafka.clients.producer.internals.RecordAccumulator#getOrCreateDeque</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> Deque&lt;RecordBatch&gt; <span class="title">getOrCreateDeque</span><span class="params">(TopicPartition tp)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 查看有没有指定tp对应的recordBatch队列</span></span><br><span class="line">    Deque&lt;RecordBatch&gt; d = <span class="keyword">this</span>.batches.get(tp);</span><br><span class="line">    <span class="keyword">if</span> (d != <span class="keyword">null</span>)</span><br><span class="line">        <span class="comment">// 如果有，就返回</span></span><br><span class="line">        <span class="keyword">return</span> d;</span><br><span class="line">    <span class="comment">// 没有的话，就新建一个</span></span><br><span class="line">    d = <span class="keyword">new</span> ArrayDeque&lt;&gt;();</span><br><span class="line">    <span class="comment">// 初始化一个空队列进去</span></span><br><span class="line">    Deque&lt;RecordBatch&gt; previous = <span class="keyword">this</span>.batches.putIfAbsent(tp, d);</span><br><span class="line">    <span class="keyword">if</span> (previous == <span class="keyword">null</span>)</span><br><span class="line">        <span class="comment">// 返回null，说明，指定tp对应的队列之前不存在，那就返回我们刚创建的队列d</span></span><br><span class="line">        <span class="keyword">return</span> d;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="comment">// 走到这里，说明并发了，别的线程给这个tp维护了一个队列，那么我们就用别的线程维护好的队列就好</span></span><br><span class="line">        <span class="keyword">return</span> previous;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// org.apache.kafka.clients.producer.internals.RecordBatch#tryAppend</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> FutureRecordMetadata <span class="title">tryAppend</span><span class="params">(<span class="keyword">long</span> timestamp, <span class="keyword">byte</span>[] key, <span class="keyword">byte</span>[] value, Callback callback, <span class="keyword">long</span> now)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 首先看看，这个recordBatch里的records里还有没有足够的空间，容纳我们新发送的消息</span></span><br><span class="line">    <span class="keyword">if</span> (!<span class="keyword">this</span>.records.hasRoomFor(key, value)) &#123;</span><br><span class="line">        <span class="comment">// 走到这里，说明，没有空间了，返回null</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">long</span> checksum = <span class="keyword">this</span>.records.append(offsetCounter++, timestamp, key, value);</span><br><span class="line">        <span class="comment">// 更新下我们这个recordBatch里记录的最大的消息</span></span><br><span class="line">        <span class="keyword">this</span>.maxRecordSize = Math.max(<span class="keyword">this</span>.maxRecordSize, Record.recordSize(key, value));</span><br><span class="line">        <span class="comment">// 更新下插入这条消息的时间</span></span><br><span class="line">        <span class="keyword">this</span>.lastAppendTime = now;</span><br><span class="line">        FutureRecordMetadata future = <span class="keyword">new</span> FutureRecordMetadata(<span class="keyword">this</span>.produceFuture, <span class="keyword">this</span>.recordCount,</span><br><span class="line">                                                               timestamp, checksum,</span><br><span class="line">                                                               key == <span class="keyword">null</span> ? -<span class="number">1</span> : key.length,</span><br><span class="line">                                                               value == <span class="keyword">null</span> ? -<span class="number">1</span> : value.length);</span><br><span class="line">        <span class="keyword">if</span> (callback != <span class="keyword">null</span>)</span><br><span class="line">            thunks.add(<span class="keyword">new</span> Thunk(callback, future));</span><br><span class="line">        <span class="comment">// 维护下当前这个recordBatch里记录的消息数目</span></span><br><span class="line">        <span class="keyword">this</span>.recordCount++;</span><br><span class="line">        <span class="comment">// 返回我们的结果</span></span><br><span class="line">        <span class="keyword">return</span> future;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>





<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// org.apache.kafka.clients.producer.KafkaProducer#waitOnMetadata</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">long</span> <span class="title">waitOnMetadata</span><span class="params">(String topic, <span class="keyword">long</span> maxWaitMs)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">    <span class="comment">// add topic to metadata topic list if it is not there already.</span></span><br><span class="line">    <span class="keyword">if</span> (!<span class="keyword">this</span>.metadata.containsTopic(topic))</span><br><span class="line">        <span class="comment">// 如果元数据里没有包含我们要发送消息的topic，那么就把该topic维护到元数据里</span></span><br><span class="line">        <span class="keyword">this</span>.metadata.add(topic);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 如果元数据的集群信息里有该topic对应的分区信息的话，就返回0</span></span><br><span class="line">    <span class="comment">// 发送消息(doSend)也就是需要获取topic对应的分区信息而已，这里能在元数据里获取到分区信息，</span></span><br><span class="line">    <span class="comment">// 就不用往下找了</span></span><br><span class="line">    <span class="keyword">if</span> (metadata.fetch().partitionsForTopic(topic) != <span class="keyword">null</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 记录下开始时间</span></span><br><span class="line">    <span class="keyword">long</span> begin = time.milliseconds();</span><br><span class="line">    <span class="comment">// 剩余时间设置为传进来的最大等待时间，默认为60s</span></span><br><span class="line">    <span class="keyword">long</span> remainingWaitMs = maxWaitMs;</span><br><span class="line">    <span class="keyword">while</span> (metadata.fetch().partitionsForTopic(topic) == <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="comment">// 走到这里，说明，元数据里的集群中没有获取到该topic对应的分区信息</span></span><br><span class="line">        log.trace(<span class="string">"Requesting metadata update for topic &#123;&#125;."</span>, topic);</span><br><span class="line">        <span class="keyword">int</span> version = metadata.requestUpdate();</span><br><span class="line">        <span class="comment">// 唤醒sender线程</span></span><br><span class="line">        <span class="comment">// 在这里的上下文，没有发现那里有更新Metadata的代码，</span></span><br><span class="line">        <span class="comment">// 只有等待更新结果的while循环，这里有一个while循环，awaitUpdate里有一个while循环</span></span><br><span class="line">        <span class="comment">// 那我们就去看看sender线程干了些什么吧</span></span><br><span class="line">        sender.wakeup();</span><br><span class="line">        metadata.awaitUpdate(version, remainingWaitMs);</span><br><span class="line">        <span class="keyword">long</span> elapsed = time.milliseconds() - begin;</span><br><span class="line">        <span class="comment">// 如果消耗的时间大于等于传进来的最大等待时间，抛出超时异常</span></span><br><span class="line">        <span class="keyword">if</span> (elapsed &gt;= maxWaitMs)</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> TimeoutException(<span class="string">"Failed to update metadata after "</span> + maxWaitMs + <span class="string">" ms."</span>);</span><br><span class="line">        <span class="comment">// 如果需要发送消息的topic是未授权的topic，抛出topic未授权异常</span></span><br><span class="line">        <span class="keyword">if</span> (metadata.fetch().unauthorizedTopics().contains(topic))</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> TopicAuthorizationException(topic);</span><br><span class="line">        remainingWaitMs = maxWaitMs - elapsed;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 返回最后消耗的时间</span></span><br><span class="line">    <span class="keyword">return</span> time.milliseconds() - begin;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// org.apache.kafka.clients.Metadata#requestUpdate</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">int</span> <span class="title">requestUpdate</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 设置 needUpdate 为true，表明需要更新元数据</span></span><br><span class="line">    <span class="keyword">this</span>.needUpdate = <span class="keyword">true</span>;</span><br><span class="line">    <span class="comment">// 返回当前的版本号</span></span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">this</span>.version;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// org.apache.kafka.clients.Metadata#awaitUpdate</span></span><br><span class="line"><span class="comment">// 等待别人帮忙更新元数据信息</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">awaitUpdate</span><span class="params">(<span class="keyword">final</span> <span class="keyword">int</span> lastVersion, <span class="keyword">final</span> <span class="keyword">long</span> maxWaitMs)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (maxWaitMs &lt; <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">"Max time to wait for metadata updates should not be &lt; 0 milli seconds"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 获取当前时间</span></span><br><span class="line">    <span class="keyword">long</span> begin = System.currentTimeMillis();</span><br><span class="line">    <span class="comment">// 设置剩余时间为传进来的最大等待时间，默认为60s</span></span><br><span class="line">    <span class="keyword">long</span> remainingWaitMs = maxWaitMs;</span><br><span class="line">    <span class="keyword">while</span> (<span class="keyword">this</span>.version &lt;= lastVersion) &#123;</span><br><span class="line">        <span class="comment">// 走到这里，说明，当前元数据的版本号小于等于我们传进来的版本号，需要进行等待</span></span><br><span class="line">        <span class="comment">// 等待别人去更新元数据，将我们需要的将要发送消息的topic的分区信息维护到元数据中</span></span><br><span class="line">        <span class="keyword">if</span> (remainingWaitMs != <span class="number">0</span>)</span><br><span class="line">            <span class="comment">// 这里，只要剩余时间不为0，就将当前线程设置为阻塞等待状态</span></span><br><span class="line">            <span class="comment">// 当前线程的代码，如果运行到这里的话，就会陷入阻塞，走不到下边去了</span></span><br><span class="line">            wait(remainingWaitMs);</span><br><span class="line">        <span class="comment">// 如果当前线程走到这里，说明，当前线程被唤醒了或者等待时间到了，并且重新获得到了锁</span></span><br><span class="line">        <span class="keyword">long</span> elapsed = System.currentTimeMillis() - begin;</span><br><span class="line">        <span class="comment">// 如果消耗的时间大于等于传进来的最大等待时间，没得说，直接抛出超时异常</span></span><br><span class="line">        <span class="keyword">if</span> (elapsed &gt;= maxWaitMs)</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> TimeoutException(<span class="string">"Failed to update metadata after "</span> + maxWaitMs + <span class="string">" ms."</span>);</span><br><span class="line">        <span class="comment">// 如果走到这里，说明，剩余时间大于0</span></span><br><span class="line">        remainingWaitMs = maxWaitMs - elapsed;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// org.apache.kafka.clients.producer.internals.Sender#run()</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    log.debug(<span class="string">"Starting Kafka producer I/O thread."</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// main loop, runs until close is called</span></span><br><span class="line">    <span class="keyword">while</span> (running) &#123;</span><br><span class="line">        <span class="comment">// 在KafkaProducer的初始化方法里，sender#running被设置为了true，</span></span><br><span class="line">        <span class="comment">// 并且被包装到了KafkaThread里，然后start起来了</span></span><br><span class="line">        <span class="comment">// 那走到这里的话，就会进入这个while循环里，</span></span><br><span class="line">        <span class="comment">// 除非调用了Sender#forceClose或者Sender#initiateClose</span></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            run(time.milliseconds());</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            log.error(<span class="string">"Uncaught error in kafka producer I/O thread: "</span>, e);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    log.debug(<span class="string">"Beginning shutdown of Kafka producer I/O thread, sending remaining records."</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// okay we stopped accepting requests but there may still be</span></span><br><span class="line">    <span class="comment">// requests in the accumulator or waiting for acknowledgment,</span></span><br><span class="line">    <span class="comment">// wait until these are completed.</span></span><br><span class="line">    <span class="keyword">while</span> (!forceClose &amp;&amp; (<span class="keyword">this</span>.accumulator.hasUnsent() || <span class="keyword">this</span>.client.inFlightRequestCount() &gt; <span class="number">0</span>)) &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            run(time.milliseconds());</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            log.error(<span class="string">"Uncaught error in kafka producer I/O thread: "</span>, e);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (forceClose) &#123;</span><br><span class="line">        <span class="comment">// We need to fail all the incomplete batches and wake up the threads waiting on</span></span><br><span class="line">        <span class="comment">// the futures.</span></span><br><span class="line">        <span class="keyword">this</span>.accumulator.abortIncompleteBatches();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">this</span>.client.close();</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">        log.error(<span class="string">"Failed to close network client"</span>, e);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    log.debug(<span class="string">"Shutdown of Kafka producer I/O thread has completed."</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// org.apache.kafka.clients.producer.internals.Sender#run(long)</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">run</span><span class="params">(<span class="keyword">long</span> now)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 获取集群信息</span></span><br><span class="line">    Cluster cluster = metadata.fetch();</span><br><span class="line">    <span class="comment">// get the list of partitions with data ready to send</span></span><br><span class="line">    RecordAccumulator.ReadyCheckResult result = <span class="keyword">this</span>.accumulator.ready(cluster, now);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// if there are any partitions whose leaders are not known yet, force metadata update</span></span><br><span class="line">    <span class="keyword">if</span> (result.unknownLeadersExist)</span><br><span class="line">        <span class="comment">// </span></span><br><span class="line">        <span class="keyword">this</span>.metadata.requestUpdate();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// remove any nodes we aren't ready to send to</span></span><br><span class="line">    Iterator&lt;Node&gt; iter = result.readyNodes.iterator();</span><br><span class="line">    <span class="keyword">long</span> notReadyTimeout = Long.MAX_VALUE;</span><br><span class="line">    <span class="keyword">while</span> (iter.hasNext()) &#123;</span><br><span class="line">        Node node = iter.next();</span><br><span class="line">        <span class="keyword">if</span> (!<span class="keyword">this</span>.client.ready(node, now)) &#123;</span><br><span class="line">            iter.remove();</span><br><span class="line">            notReadyTimeout = Math.min(notReadyTimeout, <span class="keyword">this</span>.client.connectionDelay(node, now));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// create produce requests</span></span><br><span class="line">    Map&lt;Integer, List&lt;RecordBatch&gt;&gt; batches = <span class="keyword">this</span>.accumulator.drain(cluster,</span><br><span class="line">                                                                     result.readyNodes,</span><br><span class="line">                                                                     <span class="keyword">this</span>.maxRequestSize,</span><br><span class="line">                                                                     now);</span><br><span class="line">    <span class="keyword">if</span> (guaranteeMessageOrder) &#123;</span><br><span class="line">        <span class="comment">// Mute all the partitions drained</span></span><br><span class="line">        <span class="keyword">for</span> (List&lt;RecordBatch&gt; batchList : batches.values()) &#123;</span><br><span class="line">            <span class="keyword">for</span> (RecordBatch batch : batchList)</span><br><span class="line">                <span class="keyword">this</span>.accumulator.mutePartition(batch.topicPartition);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    List&lt;RecordBatch&gt; expiredBatches = <span class="keyword">this</span>.accumulator.abortExpiredBatches(<span class="keyword">this</span>.requestTimeout, now);</span><br><span class="line">    <span class="comment">// update sensors</span></span><br><span class="line">    <span class="keyword">for</span> (RecordBatch expiredBatch : expiredBatches)</span><br><span class="line">        <span class="keyword">this</span>.sensors.recordErrors(expiredBatch.topicPartition.topic(), expiredBatch.recordCount);</span><br><span class="line"></span><br><span class="line">    sensors.updateProduceRequestMetrics(batches);</span><br><span class="line">    List&lt;ClientRequest&gt; requests = createProduceRequests(batches, now);</span><br><span class="line">    <span class="comment">// If we have any nodes that are ready to send + have sendable data, poll with 0 timeout so this can immediately</span></span><br><span class="line">    <span class="comment">// loop and try sending more data. Otherwise, the timeout is determined by nodes that have partitions with data</span></span><br><span class="line">    <span class="comment">// that isn't yet sendable (e.g. lingering, backing off). Note that this specifically does not include nodes</span></span><br><span class="line">    <span class="comment">// with sendable data that aren't ready to send since they would cause busy looping.</span></span><br><span class="line">    <span class="keyword">long</span> pollTimeout = Math.min(result.nextReadyCheckDelayMs, notReadyTimeout);</span><br><span class="line">    <span class="keyword">if</span> (result.readyNodes.size() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        log.trace(<span class="string">"Nodes with data ready to send: &#123;&#125;"</span>, result.readyNodes);</span><br><span class="line">        log.trace(<span class="string">"Created &#123;&#125; produce requests: &#123;&#125;"</span>, requests.size(), requests);</span><br><span class="line">        pollTimeout = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span> (ClientRequest request : requests)</span><br><span class="line">        client.send(request, now);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// if some partitions are already ready to be sent, the select time would be 0;</span></span><br><span class="line">    <span class="comment">// otherwise if some partition already has some data accumulated but not ready yet,</span></span><br><span class="line">    <span class="comment">// the select time will be the time difference between now and its linger expiry time;</span></span><br><span class="line">    <span class="comment">// otherwise the select time will be the time difference between now and the metadata expiry time;</span></span><br><span class="line">    <span class="keyword">this</span>.client.poll(pollTimeout, now);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// org.apache.kafka.clients.producer.internals.RecordAccumulator#ready</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> ReadyCheckResult <span class="title">ready</span><span class="params">(Cluster cluster, <span class="keyword">long</span> nowMs)</span> </span>&#123;</span><br><span class="line">    Set&lt;Node&gt; readyNodes = <span class="keyword">new</span> HashSet&lt;&gt;();</span><br><span class="line">    <span class="keyword">long</span> nextReadyCheckDelayMs = Long.MAX_VALUE;</span><br><span class="line">    <span class="comment">// 默认是不存在leader未知的情况的</span></span><br><span class="line">    <span class="keyword">boolean</span> unknownLeadersExist = <span class="keyword">false</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 等待队列的元素数量大于0，说明，内存空间已经耗尽</span></span><br><span class="line">    <span class="keyword">boolean</span> exhausted = <span class="keyword">this</span>.free.queued() &gt; <span class="number">0</span>;</span><br><span class="line">    <span class="comment">// 刚开始的时候，doSend方法还没有调用 accumulator.append 往batches里维护数据</span></span><br><span class="line">    <span class="comment">// 当 doSend 执行完 accumulator.append，batches里就有一些数据了</span></span><br><span class="line">    <span class="keyword">for</span> (Map.Entry&lt;TopicPartition, Deque&lt;RecordBatch&gt;&gt; entry : <span class="keyword">this</span>.batches.entrySet()) &#123;</span><br><span class="line">        TopicPartition part = entry.getKey();</span><br><span class="line">        Deque&lt;RecordBatch&gt; deque = entry.getValue();</span><br><span class="line"></span><br><span class="line">        Node leader = cluster.leaderFor(part);</span><br><span class="line">        <span class="keyword">if</span> (leader == <span class="keyword">null</span>) &#123;</span><br><span class="line">            unknownLeadersExist = <span class="keyword">true</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (!readyNodes.contains(leader) &amp;&amp; !muted.contains(part)) &#123;</span><br><span class="line">            <span class="keyword">synchronized</span> (deque) &#123;</span><br><span class="line">                RecordBatch batch = deque.peekFirst();</span><br><span class="line">                <span class="keyword">if</span> (batch != <span class="keyword">null</span>) &#123;</span><br><span class="line">                    <span class="keyword">boolean</span> backingOff = batch.attempts &gt; <span class="number">0</span> &amp;&amp; batch.lastAttemptMs + retryBackoffMs &gt; nowMs;</span><br><span class="line">                    <span class="keyword">long</span> waitedTimeMs = nowMs - batch.lastAttemptMs;</span><br><span class="line">                    <span class="keyword">long</span> timeToWaitMs = backingOff ? retryBackoffMs : lingerMs;</span><br><span class="line">                    <span class="keyword">long</span> timeLeftMs = Math.max(timeToWaitMs - waitedTimeMs, <span class="number">0</span>);</span><br><span class="line">                    <span class="keyword">boolean</span> full = deque.size() &gt; <span class="number">1</span> || batch.records.isFull();</span><br><span class="line">                    <span class="keyword">boolean</span> expired = waitedTimeMs &gt;= timeToWaitMs;</span><br><span class="line">                    <span class="keyword">boolean</span> sendable = full || expired || exhausted || closed || flushInProgress();</span><br><span class="line">                    <span class="keyword">if</span> (sendable &amp;&amp; !backingOff) &#123;</span><br><span class="line">                        readyNodes.add(leader);</span><br><span class="line">                    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                        <span class="comment">// Note that this results in a conservative estimate since an un-sendable partition may have</span></span><br><span class="line">                        <span class="comment">// a leader that will later be found to have sendable data. However, this is good enough</span></span><br><span class="line">                        <span class="comment">// since we'll just wake up and then sleep again for the remaining time.</span></span><br><span class="line">                        nextReadyCheckDelayMs = Math.min(timeLeftMs, nextReadyCheckDelayMs);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 刚开始的时候，doSend 方法还没有调用 accumulator.append 往 batches 里维护数据</span></span><br><span class="line">    <span class="comment">// 这里返回的 readyNodes 是空的集合， nextReadyCheckDelayMs 是默认的Long.MAX_VALUE</span></span><br><span class="line">    <span class="comment">// unknownLeadersExist 是默认的false</span></span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> ReadyCheckResult(readyNodes, nextReadyCheckDelayMs, unknownLeadersExist);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// org.apache.kafka.clients.producer.KafkaProducer#partition</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">int</span> <span class="title">partition</span><span class="params">(ProducerRecord&lt;K, V&gt; record, <span class="keyword">byte</span>[] serializedKey , <span class="keyword">byte</span>[] serializedValue, Cluster cluster)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 获取 record 上的 partition 属性，通常这个属性没有直接设置</span></span><br><span class="line">    Integer partition = record.partition();</span><br><span class="line">    <span class="keyword">if</span> (partition != <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="comment">// 走到这里，说明，record里设置了partition信息</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 元数据里维护了 topic 到 partition集合的映射</span></span><br><span class="line">        <span class="comment">// 如果producerRecord设置了partition这个属性，那么可以直接使用该partition</span></span><br><span class="line">        List&lt;PartitionInfo&gt; partitions = cluster.partitionsForTopic(record.topic());</span><br><span class="line">        <span class="keyword">int</span> lastPartition = partitions.size() - <span class="number">1</span>;</span><br><span class="line">        <span class="comment">// 当然，要校验下传过来的 partition 的合法性，瞎传的话，就给你一个异常</span></span><br><span class="line">        <span class="keyword">if</span> (partition &lt; <span class="number">0</span> || partition &gt; lastPartition) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(String.format(<span class="string">"Invalid partition given with record: %d is not in the range [0...%d]."</span>, partition, lastPartition));</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 返回producerRecord里维护的partition</span></span><br><span class="line">        <span class="keyword">return</span> partition;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 如果没有在record里设置partition，那么就得通过分区器来实现分区了</span></span><br><span class="line">    <span class="comment">// 分区器对应的分区逻辑在：https://llrrbaba.github.io/2021/07/27/Kafka%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB-Partitioner%E6%8E%A5%E5%8F%A3%E7%AE%80%E6%9E%90/，可以看到</span></span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">this</span>.partitioner.partition(record.topic(), record.key(), serializedKey, record.value(), serializedValue,</span><br><span class="line">        cluster);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>





<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// org.apache.kafka.clients.producer.internals.RecordAccumulator#append</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> RecordAppendResult <span class="title">append</span><span class="params">(TopicPartition tp,</span></span></span><br><span class="line"><span class="function"><span class="params">                                 <span class="keyword">long</span> timestamp,</span></span></span><br><span class="line"><span class="function"><span class="params">                                 <span class="keyword">byte</span>[] key,</span></span></span><br><span class="line"><span class="function"><span class="params">                                 <span class="keyword">byte</span>[] value,</span></span></span><br><span class="line"><span class="function"><span class="params">                                 Callback callback,</span></span></span><br><span class="line"><span class="function"><span class="params">                                 <span class="keyword">long</span> maxTimeToBlock)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">    <span class="comment">// 维护下执行 append 操作的线程数目</span></span><br><span class="line">    appendsInProgress.incrementAndGet();</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// 获取 RecordBatch 集合</span></span><br><span class="line">        Deque&lt;RecordBatch&gt; dq = getOrCreateDeque(tp);</span><br><span class="line">        <span class="keyword">synchronized</span> (dq) &#123;</span><br><span class="line">            <span class="comment">// 可以看到，这里对 dq 进行了加锁操作</span></span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> (closed)</span><br><span class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> IllegalStateException(<span class="string">"Cannot send after the producer is closed."</span>);</span><br><span class="line">            <span class="comment">// </span></span><br><span class="line">            RecordAppendResult appendResult = tryAppend(timestamp, key, value, callback, dq);</span><br><span class="line">            <span class="keyword">if</span> (appendResult != <span class="keyword">null</span>)</span><br><span class="line">                <span class="keyword">return</span> appendResult;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// we don't have an in-progress record batch try to allocate a new batch</span></span><br><span class="line">        <span class="keyword">int</span> size = Math.max(<span class="keyword">this</span>.batchSize, Records.LOG_OVERHEAD + Record.recordSize(key, value));</span><br><span class="line">        log.trace(<span class="string">"Allocating a new &#123;&#125; byte message buffer for topic &#123;&#125; partition &#123;&#125;"</span>, size, tp.topic(), tp.partition());</span><br><span class="line">        ByteBuffer buffer = free.allocate(size, maxTimeToBlock);</span><br><span class="line">        <span class="keyword">synchronized</span> (dq) &#123;</span><br><span class="line">            <span class="comment">// Need to check if producer is closed again after grabbing the dequeue lock.</span></span><br><span class="line">            <span class="keyword">if</span> (closed)</span><br><span class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> IllegalStateException(<span class="string">"Cannot send after the producer is closed."</span>);</span><br><span class="line"></span><br><span class="line">            RecordAppendResult appendResult = tryAppend(timestamp, key, value, callback, dq);</span><br><span class="line">            <span class="keyword">if</span> (appendResult != <span class="keyword">null</span>) &#123;</span><br><span class="line">                <span class="comment">// Somebody else found us a batch, return the one we waited for! Hopefully this doesn't happen often...</span></span><br><span class="line">                free.deallocate(buffer);</span><br><span class="line">                <span class="keyword">return</span> appendResult;</span><br><span class="line">            &#125;</span><br><span class="line">            MemoryRecords records = MemoryRecords.emptyRecords(buffer, compression, <span class="keyword">this</span>.batchSize);</span><br><span class="line">            RecordBatch batch = <span class="keyword">new</span> RecordBatch(tp, records, time.milliseconds());</span><br><span class="line">            FutureRecordMetadata future = Utils.notNull(batch.tryAppend(timestamp, key, value, callback, time.milliseconds()));</span><br><span class="line"></span><br><span class="line">            dq.addLast(batch);</span><br><span class="line">            incomplete.add(batch);</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">new</span> RecordAppendResult(future, dq.size() &gt; <span class="number">1</span> || batch.records.isFull(), <span class="keyword">true</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        appendsInProgress.decrementAndGet();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// org.apache.kafka.clients.producer.internals.RecordAccumulator#getOrCreateDeque</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> Deque&lt;RecordBatch&gt; <span class="title">getOrCreateDeque</span><span class="params">(TopicPartition tp)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 获取 RecordAccumulator 中该 tp 对应的 RecordBatch 集合信息</span></span><br><span class="line">    Deque&lt;RecordBatch&gt; d = <span class="keyword">this</span>.batches.get(tp);</span><br><span class="line">    <span class="keyword">if</span> (d != <span class="keyword">null</span>)</span><br><span class="line">        <span class="comment">// 走到这里，说明获取到了，返回即可</span></span><br><span class="line">        <span class="keyword">return</span> d;</span><br><span class="line">    <span class="comment">// 否则，新建一个集合</span></span><br><span class="line">    d = <span class="keyword">new</span> ArrayDeque&lt;&gt;();</span><br><span class="line">    <span class="comment">// 将该新建的集合维护到 RecordAccumulator#batches 中</span></span><br><span class="line">    Deque&lt;RecordBatch&gt; previous = <span class="keyword">this</span>.batches.putIfAbsent(tp, d);</span><br><span class="line">    <span class="comment">// RecordAccumulator#batches 是个线程安全的 map</span></span><br><span class="line">    <span class="keyword">if</span> (previous == <span class="keyword">null</span>)</span><br><span class="line">        <span class="comment">// 如果没有并发的话，就返回我们维护进去的空集合就好</span></span><br><span class="line">        <span class="keyword">return</span> d;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="comment">// 有并发的话，就将别的线程维护进去的 RecordBatch 集合返回</span></span><br><span class="line">        <span class="keyword">return</span> previous;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// org.apache.kafka.clients.producer.internals.RecordAccumulator#tryAppend</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> RecordAppendResult <span class="title">tryAppend</span><span class="params">(<span class="keyword">long</span> timestamp, <span class="keyword">byte</span>[] key, <span class="keyword">byte</span>[] value, Callback callback, Deque&lt;RecordBatch&gt; deque)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 这里就用到了双端队列的特性了，可以指定获取队尾的元素</span></span><br><span class="line">    RecordBatch last = deque.peekLast();</span><br><span class="line">    <span class="keyword">if</span> (last != <span class="keyword">null</span>) &#123;</span><br><span class="line">        FutureRecordMetadata future = last.tryAppend(timestamp, key, value, callback, time.milliseconds());</span><br><span class="line">        <span class="keyword">if</span> (future == <span class="keyword">null</span>)</span><br><span class="line">            <span class="comment">// 如果走到这里，说明 MemoryRecords 写满了，没办法写入该条消息</span></span><br><span class="line">            last.records.close();</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">new</span> RecordAppendResult(future, deque.size() &gt; <span class="number">1</span> || last.records.isFull(), <span class="keyword">false</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// org.apache.kafka.clients.producer.internals.RecordBatch#tryAppend</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> FutureRecordMetadata <span class="title">tryAppend</span><span class="params">(<span class="keyword">long</span> timestamp, <span class="keyword">byte</span>[] key, <span class="keyword">byte</span>[] value, Callback callback, <span class="keyword">long</span> now)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (!<span class="keyword">this</span>.records.hasRoomFor(key, value)) &#123;</span><br><span class="line">        <span class="comment">// 走到这里，说明，没办法写入该消息</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// 写入该条消息</span></span><br><span class="line">        <span class="keyword">long</span> checksum = <span class="keyword">this</span>.records.append(offsetCounter++, timestamp, key, value);</span><br><span class="line">        <span class="keyword">this</span>.maxRecordSize = Math.max(<span class="keyword">this</span>.maxRecordSize, Record.recordSize(key, value));</span><br><span class="line">        <span class="keyword">this</span>.lastAppendTime = now;</span><br><span class="line">        FutureRecordMetadata future = <span class="keyword">new</span> FutureRecordMetadata(<span class="keyword">this</span>.produceFuture, <span class="keyword">this</span>.recordCount, timestamp, checksum, key == <span class="keyword">null</span> ? -<span class="number">1</span> : key.length, value == <span class="keyword">null</span> ? -<span class="number">1</span> : value.length);</span><br><span class="line">        <span class="keyword">if</span> (callback != <span class="keyword">null</span>)</span><br><span class="line">            thunks.add(<span class="keyword">new</span> Thunk(callback, future));</span><br><span class="line">        <span class="keyword">this</span>.recordCount++;</span><br><span class="line">        <span class="comment">// 返回一个 future 对象</span></span><br><span class="line">        <span class="keyword">return</span> future;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// org.apache.kafka.common.record.MemoryRecords#hasRoomFor</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">hasRoomFor</span><span class="params">(<span class="keyword">byte</span>[] key, <span class="keyword">byte</span>[] value)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 如果调用了 MemoryRecords#close 的话，就会变得不可写，那么就返回false</span></span><br><span class="line">    <span class="keyword">if</span> (!<span class="keyword">this</span>.writable)</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 如果没有写入过 record 的话，</span></span><br><span class="line">    <span class="comment">// 就要保证 "写入的消息大小 + LOG_OVERHEAD" 不能超过 MemoryRecords 的初始容量</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 如果有写入过 record 的话，就要保证 "写入的消息大小 + 已经写入的消息的压缩大小 + LOG_OVERHEAD"</span></span><br><span class="line">    <span class="comment">// 不能超过 writeLimit，(writeLimi 就是一个 batchSize 的大小)</span></span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">this</span>.compressor.numRecordsWritten() == <span class="number">0</span> ?</span><br><span class="line">        <span class="keyword">this</span>.initialCapacity &gt;= Records.LOG_OVERHEAD + Record.recordSize(key, value) :</span><br><span class="line">        <span class="keyword">this</span>.writeLimit &gt;= <span class="keyword">this</span>.compressor.estimatedBytesWritten() + Records.LOG_OVERHEAD + Record.recordSize(key, value);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// org.apache.kafka.common.record.MemoryRecords#append(long, long, byte[], byte[])    </span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">append</span><span class="params">(<span class="keyword">long</span> offset, <span class="keyword">long</span> timestamp, <span class="keyword">byte</span>[] key, <span class="keyword">byte</span>[] value)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 如果调用了 MemoryRecords#close 的话，就会变得不可写，那么就抛出一个异常</span></span><br><span class="line">    <span class="keyword">if</span> (!writable)</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IllegalStateException(<span class="string">"Memory records is not writable"</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 获取 该条消息的大小</span></span><br><span class="line">    <span class="keyword">int</span> size = Record.recordSize(key, value);</span><br><span class="line">    <span class="comment">// 将该消息对应的 offset size 时间戳 key value 通过 compressor 写入</span></span><br><span class="line">    <span class="comment">// 并维护了一个 org.apache.kafka.common.record.Record 对象</span></span><br><span class="line">    compressor.putLong(offset);</span><br><span class="line">    compressor.putInt(size);</span><br><span class="line">    <span class="keyword">long</span> crc = compressor.putRecord(timestamp, key, value);</span><br><span class="line">    compressor.recordWritten(size + Records.LOG_OVERHEAD);</span><br><span class="line">    <span class="keyword">return</span> crc;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Kafka/" rel="tag"># Kafka</a>
          
            <a href="/tags/%E6%BA%90%E7%A0%81/" rel="tag"># 源码</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2021/07/27/Kafka%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB-7-KafkaConsumer%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/" rel="next" title="Kafka源码阅读-7-KafkaConsumer-subscribe源码阅读">
                <i class="fa fa-chevron-left"></i> Kafka源码阅读-7-KafkaConsumer-subscribe源码阅读
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2021/07/27/Kafka%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB-8-KafkaConsumer-poll%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/" rel="prev" title="Kafka源码阅读-8-KafkaConsumer-poll源码阅读">
                Kafka源码阅读-8-KafkaConsumer-poll源码阅读 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">llrrbaba</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives">
              
                  <span class="site-state-item-count">34</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">9</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">10</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">llrrbaba</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>





  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
